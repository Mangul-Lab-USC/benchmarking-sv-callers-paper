{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install conda install -c conda-forge scikit-allel\n",
    "import pandas as pd\n",
    "import allel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=['AKR_J','A_J','BALB_cJ','C3H_HeJ','CBA_J','DBA_2J','LP_J']\n",
    "# tools=['sniffles']\n",
    "tools=['breakdancer',\n",
    "#'clever',\n",
    "'delly',\n",
    "'gasv',\n",
    "'gridss',\n",
    "#'indelminer',\n",
    "#'lumpexpress',\n",
    "#'mistrvar',\n",
    "#'pindel',\n",
    "#'platypus',\n",
    "'popdel',\n",
    "'smoove',\n",
    "'crest',\n",
    "'genomestrip',\n",
    "'manta_diploidSV'\n",
    "#'sniffles'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AKR_J ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vs/.local/lib/python3.5/site-packages/ipykernel_launcher.py:35: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- A_J ---\n",
      "--- BALB_cJ ---\n",
      "--- C3H_HeJ ---\n"
     ]
    }
   ],
   "source": [
    "#tools\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "#cov_list=['32','8','4','2','1','0.5','0.1']\n",
    "#cov_list=['32','8','4','2']\n",
    "cov_list=['32','16','8','4','2','1','0.5','0.1']\n",
    "th_list=['0','10','100','1000','10000']\n",
    "n_list=['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "\n",
    "#n_list=['1']\n",
    "\n",
    "\n",
    "df= pd.DataFrame(columns=['strain','length','flag','position','threshold'])\n",
    "\n",
    "\n",
    "\n",
    "for s in samples:\n",
    "    print (\"---\",s,\"---\")\n",
    "    for t in tools:\n",
    "        for th in th_list: \n",
    "            for cov in cov_list:\n",
    "                for n in n_list:\n",
    "            \n",
    "            \n",
    "                    file='../Data/raw_data/mouse/custom_vcf_'+cov+'x/'+str(th)+'t/nf_'+str(th)+'t.'+t+'.'+s+'.chr19.'+cov+'p.'+n+'_sorted.modified.vcf'\n",
    "            \n",
    "                    if path.exists(file):\n",
    "                        callset = allel.read_vcf(file,fields='*')\n",
    "                        if callset!=None:\n",
    "                            df_current = pd.DataFrame({'tool': t, 'strain': s, 'length': callset['variants/SVLEN'],'flag': callset['variants/FLAG'],'position': callset['variants/POS'],'threshold': th})\n",
    "                            df_current['cov']=cov\n",
    "                            df_current['n']=n\n",
    "                            df = pd.concat([df_current, df],ignore_index=True) \n",
    "#                         else:\n",
    "#                             print(\"Empty File: \" + file)\n",
    "\n",
    "#                     else:\n",
    "#                         print(\"Nonexistant File: \" + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "# cov_list=['32','8','4','2','1','0.5','0.1']\n",
    "\n",
    "cov_list=['32','16','8','4','2','1','0.5','0.1']\n",
    "th_list=['0','10','100','1000','10000']\n",
    "#th_list=['1000']\n",
    "n_list=['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "\n",
    "#n_list=['1','2']\n",
    "\n",
    "\n",
    "df_nondel= pd.DataFrame(columns=['strain','length','flag','position','threshold'])\n",
    "\n",
    "\n",
    "\n",
    "for s in samples:\n",
    "    print (\"---\",s,\"---\")\n",
    "    for t in tools:\n",
    "        for th in th_list: \n",
    "            for cov in cov_list:\n",
    "                for n in n_list:\n",
    "            \n",
    "            \n",
    "                    file='../Data/raw_data/mouse/custom_vcf_'+cov+'x/'+str(th)+'t/nf_'+str(th)+'t.'+t+'.'+s+'.chr19.'+cov+'p.'+n+'_sorted.modified.nondel.vcf'\n",
    "            \n",
    "                    if path.exists(file):\n",
    "                        callset = allel.read_vcf(file,fields='*')\n",
    "                        if callset!=None:\n",
    "                            df_current = pd.DataFrame({'tool': t, 'strain': s, 'length': callset['variants/SVLEN'],'flag': callset['variants/FLAG'],'position': callset['variants/POS'],'threshold': th})\n",
    "                            df_current['cov']=cov\n",
    "                            df_current['n']=n\n",
    "                            df_nondel = pd.concat([df_current, df_nondel],ignore_index=True)   \n",
    "                    else:\n",
    "                        print (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nondel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group by TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data_TP=df[df['flag'] == 'TP'].groupby(['tool','threshold','strain','n','cov'],as_index=False)['flag'].count()\n",
    "group_data_TP=group_data_TP.rename(columns={\"flag\": \"nTP\"})\n",
    "\n",
    "\n",
    "group_data_TP[pd.isnull(group_data_TP).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data_FP=df[df['flag'] == 'FP'].groupby(['tool','threshold','strain','n','cov'],as_index=False)['flag'].count()\n",
    "group_data_FP=group_data_FP.rename(columns={\"flag\": \"nFP\"})\n",
    "group_data_FP.tail()\n",
    "\n",
    "\n",
    "group_data_FP[pd.isnull(group_data_FP).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data_TN=df_nondel[df_nondel['flag'] == 'TN'].groupby(['tool','threshold','strain','n','cov'],as_index=False)['flag'].count()\n",
    "group_data_TN=group_data_TN.rename(columns={\"flag\": \"nTN\"})\n",
    "\n",
    "\n",
    "group_data_TN[pd.isnull(group_data_TN).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill mssing combinations with 0s\n",
    "for s in samples:\n",
    "    for t in tools:\n",
    "        for th in th_list:\n",
    "            for cov in cov_list:\n",
    "                for n in n_list:\n",
    "                    if not (((group_data_TP['cov'] == cov) & (group_data_TP['n'] == n) & (group_data_TP['tool'] == t) & (group_data_TP['strain'] == s) & (group_data_TP['threshold'] == th)).any()):\n",
    "                        group_data_TP = group_data_TP.append({'cov' : cov , 'n' : n , 'tool' : t , 'strain' : s,'threshold' : th,'nTP' : 0.0} , ignore_index=True)\n",
    "group_data_TP[pd.isnull(group_data_TP).any(axis=1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill mssing combinations with 0s\n",
    "for s in samples:\n",
    "    for t in tools:\n",
    "        for th in th_list:\n",
    "            for cov in cov_list:\n",
    "                for n in n_list:\n",
    "                    if not (((group_data_FP['cov'] == cov) & (group_data_FP['n'] == n) & (group_data_FP['tool'] == t) & (group_data_FP['strain'] == s) & (group_data_FP['threshold'] == th)).any()):\n",
    "                        group_data_FP = group_data_FP.append({'cov' : cov , 'n' : n , 'tool' : t , 'strain' : s,'threshold' : th,'nFP' : 0.0} , ignore_index=True)\n",
    "group_data_FP[pd.isnull(group_data_FP).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill mssing combinations with 0s\n",
    "for s in samples:\n",
    "    for t in tools:\n",
    "        for th in th_list:\n",
    "            for cov in cov_list:\n",
    "                for n in n_list:\n",
    "                    if not (((group_data_TN['cov'] == cov) & (group_data_TN['n'] == n) & (group_data_TN['tool'] == t) & (group_data_TN['strain'] == s) & (group_data_TN['threshold'] == th)).any()):\n",
    "                        group_data_TN = group_data_TN.append({'cov' : cov , 'n' : n , 'tool' : t , 'strain' : s,'threshold' : th,'nTN' : 0.0} , ignore_index=True)\n",
    "group_data_TN[pd.isnull(group_data_TN).any(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data_TN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now both TP and FP are the size size and we can merge\n",
    "df_merge=pd.merge(group_data_TP, group_data_FP,on=['tool','threshold','strain','n','cov'])\n",
    "df_merge=pd.merge(df_merge, group_data_TN,on=['tool','threshold','strain','n','cov'])\n",
    "df_merge[pd.isnull(df_merge).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#true SVs\n",
    "df_current = pd.DataFrame(columns=['strain','length'])\n",
    "df_true = pd.DataFrame(columns=['strain','length'])\n",
    "\n",
    "\n",
    "for s in samples:\n",
    "    file='../Data/gold_standard/mouse_vcf/'+s+'_reference.vcf'\n",
    "    callset = allel.read_vcf(file,fields='*')\n",
    "    \n",
    "    df_current = pd.DataFrame({'strain': s, 'length': callset['variants/SVLEN']})\n",
    "    df_true = pd.concat([df_current, df_true],ignore_index=True)\n",
    "group_data_true = df_true.groupby(['strain'],as_index=False).count()\n",
    "group_data_true=group_data_true.rename(columns={\"length\": \"n_true\"})\n",
    "group_data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge=pd.merge(df_merge, group_data_true)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv(r'FigureS10_coverage.csv')\n",
    "# df_merge = pd.read_csv('Figure3_df_merge.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
